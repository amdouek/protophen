# ProToPhen Default Configuration
# ================================
# This file contains the default settings for ProToPhen experiments.
# Copy and modify for your specific experiment.

experiment_name: "default"
description: "Default ProToPhen configuration"
tags:
  - baseline

# Data Configuration
data:
  protein_library_path: null  # Path to protein library JSON/FASTA
  phenotype_data_path: null   # Path to phenotype data
  cache_dir: "./cache"
  output_dir: "./outputs"
  
  min_sequence_length: 10
  max_sequence_length: 2000
  
  train_fraction: 0.8
  val_fraction: 0.1
  test_fraction: 0.1
  split_seed: 42

# Embedding Configuration
embedding:
  # ESM-2 model (larger = better but slower)
  # Options: esm2_t6_8M_UR50D, esm2_t12_35M_UR50D, esm2_t30_150M_UR50D, 
  #          esm2_t33_650M_UR50D, esm2_t36_3B_UR50D
  esm_model_name: "esm2_t33_650M_UR50D"
  esm_layer: -1  # -1 = last layer
  esm_pooling: "mean"  # mean, cls, max
  
  use_structure: false
  esmfold_chunk_size: null
  
  include_physicochemical: true
  fusion_method: "concatenate"
  
  batch_size: 8
  device: "cuda"
  use_fp16: true

# Phenotype Configuration
phenotype:
  feature_selection_method: "variance"
  n_features_to_keep: null
  
  plate_normalisation: "robust_mad"
  feature_normalisation: "standardise"
  
  batch_correction_method: null
  
  clip_outliers: true
  outlier_threshold: 5.0

# Model Configuration
model:
  protein_embedding_dim: 1280
  hidden_dims: [512, 256]
  dropout: 0.1
  activation: "gelu"
  
  predict_cell_painting: true
  predict_viability: true
  predict_transcriptomics: false
  
  cell_painting_dim: 1500
  
  task_weights:
    cell_painting: 1.0
    viability: 0.5
    transcriptomics: 0.5

# Training Configuration
training:
  learning_rate: 0.0001
  weight_decay: 0.01
  optimiser: "adamw"
  scheduler: "cosine"
  warmup_steps: 100
  
  epochs: 100
  batch_size: 32
  gradient_accumulation_steps: 1
  max_grad_norm: 1.0
  
  early_stopping: true
  patience: 10
  min_delta: 0.0001
  
  save_every_n_epochs: 5
  keep_n_checkpoints: 3
  
  log_every_n_steps: 10
  eval_every_n_epochs: 1
  
  seed: 42

# Active Learning Configuration
active_learning:
  uncertainty_method: "mc_dropout"
  n_mc_samples: 20
  
  acquisition_function: "expected_improvement"
  
  batch_size: 10
  diversity_weight: 0.3
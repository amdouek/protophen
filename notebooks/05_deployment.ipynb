{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a66c21ae",
   "metadata": {},
   "source": [
    "# 05: ProToPhen Deployment Infrastructure\n",
    "\n",
    "**Session 10 Documentation Notebook**\n",
    "\n",
    "This notebook demonstrates the production-serving components of ProToPhen:\n",
    "\n",
    "1. **Inference Pipeline** — End-to-end sequence to phenotype prediction\n",
    "2. **Checkpoint Compatibility** — Loading Trainer, Callback, and Registry checkpoints\n",
    "3. **Model Registry** — Version tracking, promotion, rollback\n",
    "4. **Monitoring & Drift Detection** — Latency, throughput, and distribution shift\n",
    "5. **Feedback & Quality Tracking** — Closing the active-learning loop\n",
    "6. **REST API** — FastAPI service for real-time and batch inference\n",
    "7. **Docker Deployment** — Containerised serving quick-start\n",
    "\n",
    "---\n",
    "\n",
    "**Prerequisites:**\n",
    "```bash\n",
    "pip install 'protophen[serving]'  # adds fastapi, uvicorn, httpx, prometheus-client\n",
    "```\n",
    "\n",
    "**Contents**\n",
    "\n",
    "0. [Setup & Synthetic Checkpoint](#0-setup--synthetic-checkpoint)\n",
    "1. [Inference Pipeline](#1-inference-pipeline)\n",
    "2. [Checkpoint Compatibility](#2-checkpoint-compatibility)\n",
    "3. [Model Registry](#3-model-registry)\n",
    "4. [Monitoring & Drift Detection](#4-monitoring--drift-detection)\n",
    "5. [Feedback & Quality Tracking](#5-feedback--quality-tracking)\n",
    "6. [REST API](#6-rest-api)\n",
    "7. [Docker deployment](#7-docker-deployment)\n",
    "8. [Configuration Reference](#8-configuration-reference)\n",
    "9. [Summary](#9-summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb60d312",
   "metadata": {},
   "source": [
    "## 0. Setup & Synthetic Checkpoint\n",
    "\n",
    "All examples in this notebook use a **tiny synthetic model** so that\n",
    "no real ESM-2 weights or GPU are required.  The same patterns apply\n",
    "to full-scale models — only the checkpoint path changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4330ae9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: C:\\Users\\adou0002\\AppData\\Local\\Temp\\protophen_deploy_f2qccnb8\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Create a temporary working directory for this notebook\n",
    "WORK_DIR = Path(tempfile.mkdtemp(prefix=\"protophen_deploy_\"))\n",
    "CHECKPOINT_DIR = WORK_DIR / \"checkpoints\"\n",
    "REGISTRY_DIR = WORK_DIR / \"model_registry\"\n",
    "FEEDBACK_DIR = WORK_DIR / \"feedback\"\n",
    "\n",
    "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Working directory: {WORK_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dced0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-18 16:38:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.models.protophen\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m | \u001b[1mInitialised ProToPhenModel: 10,915 parameters, tasks=['cell_painting', 'viability']\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 10,915 parameters\n",
      "Tasks: ['cell_painting', 'viability']\n"
     ]
    }
   ],
   "source": [
    "from protophen.models.protophen import ProToPhenConfig, ProToPhenModel\n",
    "\n",
    "# Build a tiny model for demonstration\n",
    "model_config = ProToPhenConfig(\n",
    "    protein_embedding_dim=32,\n",
    "    encoder_hidden_dims=[16],\n",
    "    encoder_output_dim=8,\n",
    "    decoder_hidden_dims=[16],\n",
    "    cell_painting_dim=10,\n",
    "    predict_viability=True,\n",
    "    predict_transcriptomics=False,\n",
    "    mc_dropout=True,\n",
    ")\n",
    "\n",
    "model = ProToPhenModel(config = model_config)\n",
    "print(f\"Model: {model.n_parameters:,} parameters\")\n",
    "print(f\"Tasks: {model.task_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c263278e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer checkpoint: C:\\Users\\adou0002\\AppData\\Local\\Temp\\protophen_deploy_f2qccnb8\\checkpoints\\trainer_best.pt\n",
      "Pipeline checkpoint: C:\\Users\\adou0002\\AppData\\Local\\Temp\\protophen_deploy_f2qccnb8\\checkpoints\\pipeline_v1.pt\n"
     ]
    }
   ],
   "source": [
    "# Save in the format Trainer.save_checkpoint() produces - this is the most common real-world checkpoint format.\n",
    "from dataclasses import asdict\n",
    "from protophen.training.trainer import TrainerConfig\n",
    "\n",
    "trainer_config = TrainerConfig(\n",
    "    epochs=100,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.01,\n",
    "    optimiser=\"adamw\",\n",
    "    scheduler=\"cosine\",\n",
    "    tasks=[\"cell_painting\", \"viability\"],\n",
    "    task_weights={\"cell_painting\": 1.0, \"viability\": 0.5},\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "trainer_ckpt_path = CHECKPOINT_DIR / \"trainer_best.pt\"\n",
    "torch.save(\n",
    "    {\n",
    "        \"epoch\": 75,\n",
    "        \"global_step\": 3750,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimiser_state_dict\": {},\n",
    "        \"config\": asdict(trainer_config),  # TrainerConfig, NOT ProToPhenConfig\n",
    "        \"best_val_loss\": 0.0312,\n",
    "    },\n",
    "    trainer_ckpt_path,\n",
    ")\n",
    "\n",
    "# Also save a pipeline-style checkpoint (with ProToPhenConfig)\n",
    "pipeline_ckpt_path = CHECKPOINT_DIR / \"pipeline_v1.pt\"\n",
    "torch.save(\n",
    "    {\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"config\": {\n",
    "            \"protein_embedding_dim\": 32,\n",
    "            \"encoder_hidden_dims\": [16],\n",
    "            \"encoder_output_dim\": 8,\n",
    "            \"decoder_hidden_dims\": [16],\n",
    "            \"cell_painting_dim\": 10,\n",
    "            \"predict_viability\": True,\n",
    "            \"predict_transcriptomics\": False,\n",
    "            \"mc_dropout\": True,\n",
    "        },\n",
    "        \"epoch\": 75,\n",
    "        \"version\": \"v1.0\",\n",
    "        \"metrics\": {\"val_r2\": 0.72, \"val_mse\": 0.031},\n",
    "    },\n",
    "    pipeline_ckpt_path,\n",
    ")\n",
    "\n",
    "print(f\"Trainer checkpoint: {trainer_ckpt_path}\")\n",
    "print(f\"Pipeline checkpoint: {pipeline_ckpt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8598f6",
   "metadata": {},
   "source": [
    "## 1. Inference Pipeline\n",
    "\n",
    "The `InferencePipeline` class encapsulates the full prediction pathway:\n",
    "\n",
    "sequence ──► ESM-2 embedding ──► physicochemical features ──► fusion\n",
    "         ──► ProToPhen model ──► task predictions (+ optional uncertainty)\n",
    "\n",
    "Heavy components (ESM-2 model, ProToPhen checkpoint) are **lazily loaded**\n",
    "on first use, so construction is cheap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "616f7e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.pipeline\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m421\u001b[0m | \u001b[1mInferencePipeline initialised (device=cpu, checkpoint=C:\\Users\\adou0002\\AppData\\Local\\Temp\\protophen_deploy_f2qccnb8\\checkpoints\\pipeline_v1.pt)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline ready: False\n",
      "Model version:  unknown\n",
      "Device:         cpu\n"
     ]
    }
   ],
   "source": [
    "from protophen.serving.pipeline import InferencePipeline, PipelineConfig\n",
    "\n",
    "config = PipelineConfig(\n",
    "    device=\"cpu\",\n",
    "    use_fp16=False,\n",
    "    # Disable physicochemical features for this demo\n",
    "    # (in production, leave these as True)\n",
    "    include_physicochemical=False,\n",
    "    # Uncertainty defaults\n",
    "    default_mc_samples=20,\n",
    "    # Sequence limits\n",
    "    max_sequence_length=2000,\n",
    "    max_batch_size=64,\n",
    ")\n",
    "\n",
    "pipeline = InferencePipeline(\n",
    "    checkpoint_path=pipeline_ckpt_path,\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "print(f\"Pipeline ready: {pipeline.is_ready}\")\n",
    "print(f\"Model version:  {pipeline.model_version}\")\n",
    "print(f\"Device:         {pipeline.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbe9c828",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.pipeline\u001b[0m:\u001b[36mload_checkpoint\u001b[0m:\u001b[36m245\u001b[0m | \u001b[1mLoading checkpoint from C:\\Users\\adou0002\\AppData\\Local\\Temp\\protophen_deploy_f2qccnb8\\checkpoints\\pipeline_v1.pt\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.models.protophen\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m | \u001b[1mInitialised ProToPhenModel: 10,915 parameters, tasks=['cell_painting', 'viability']\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.pipeline\u001b[0m:\u001b[36mbuild_model_from_checkpoint\u001b[0m:\u001b[36m344\u001b[0m | \u001b[1mModel restored (epoch 75), 10,915 params on cpu\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.pipeline\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m512\u001b[0m | \u001b[1mModel version 'v1.0' loaded successfully\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_version: v1.0\n",
      "  model_name: ProToPhen\n",
      "  tasks: {'cell_painting': 10, 'viability': 1}\n",
      "  latent_dim: 8\n",
      "  protein_embedding_dim: 32\n",
      "  n_parameters: 10915\n",
      "  n_trainable_parameters: 10915\n",
      "  encoder_hidden_dims: [16]\n",
      "  decoder_hidden_dims: [16]\n",
      "  esm_model: esm2_t33_650M_UR50D\n",
      "  fusion_method: concatenate\n",
      "  device: cpu\n",
      "  loaded_at: 2026-02-18T05:38:23.215483+00:00\n"
     ]
    }
   ],
   "source": [
    "# Inspect model metadata\n",
    "info = pipeline.get_model_info()\n",
    "for key, value in info.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5872a062",
   "metadata": {},
   "source": [
    "### 1.1 Mock the ESM Embedder\n",
    "\n",
    "In production, the pipeline calls `ESMEmbedder.embed_sequence()` to\n",
    "compute real ESM-2 embeddings.  For this demo we inject a mock that\n",
    "returns deterministic 32-dimensional vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "712e0fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest.mock import MagicMock\n",
    "\n",
    "mock_esm = MagicMock()\n",
    "mock_esm.embedding_dim = 32\n",
    "mock_esm.output_dim = 32\n",
    "mock_esm._model_loaded = True\n",
    "\n",
    "def _mock_embed(seq):\n",
    "    np.random.seed(hash(seq) % 2**31)\n",
    "    return np.random.randn(32).astype(np.float32)\n",
    "\n",
    "def _mock_embed_batch(seqs, **kw):\n",
    "    return np.stack([_mock_embed(s) for s in seqs])\n",
    "\n",
    "mock_esm.embed_sequence.side_effect = _mock_embed\n",
    "mock_esm.embed_sequences.side_effect = _mock_embed_batch\n",
    "\n",
    "# Inject mock\n",
    "pipeline._esm_embedder = mock_esm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824434f4",
   "metadata": {},
   "source": [
    "### 1.2 Single Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9286d6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.embeddings.fusion\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m423\u001b[0m | \u001b[1mInitialised EmbeddingFusion: method=concatenate\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein:          demo_protein_1\n",
      "Sequence length:  30\n",
      "Hash:             2af685c306feed93\n",
      "Model version:    v1.0\n",
      "Inference time:   30.3 ms\n",
      "\n",
      "  Task: cell_painting (10 dims)\n",
      "    First 5 values: ['0.3078', '-0.1771', '-0.0311', '-0.1844', '0.3945']\n",
      "  Task: viability (1 dims)\n",
      "    First 5 values: ['0.6807']\n"
     ]
    }
   ],
   "source": [
    "sequence = \"MKFLILLFNILCLFPVLAADNHGVGPQGAS\"\n",
    "\n",
    "result = pipeline.predict(sequence, protein_name=\"demo_protein_1\")\n",
    "\n",
    "print(f\"Protein:          {result.protein_name}\")\n",
    "print(f\"Sequence length:  {result.sequence_length}\")\n",
    "print(f\"Hash:             {result.protein_hash}\")\n",
    "print(f\"Model version:    {result.model_version}\")\n",
    "print(f\"Inference time:   {result.inference_time_ms:.1f} ms\")\n",
    "print()\n",
    "\n",
    "for pred in result.predictions:\n",
    "    vals = pred.values[:5]  # first 5 values\n",
    "    print(f\"  Task: {pred.task_name} ({pred.dimension} dims)\")\n",
    "    print(f\"    First 5 values: {[f'{v:.4f}' for v in vals]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9b41be",
   "metadata": {},
   "source": [
    "### 1.3 Prediction with Uncertainty (MC Dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52e1aabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertainty estimates:\n",
      "  Task: cell_painting\n",
      "    MC samples: 10\n",
      "    Mean σ: 0.1170, Max σ: 0.1941\n",
      "  Task: viability\n",
      "    MC samples: 10\n",
      "    Mean σ: 0.0651, Max σ: 0.0651\n"
     ]
    }
   ],
   "source": [
    "result_unc = pipeline.predict(\n",
    "    sequence,\n",
    "    protein_name=\"demo_protein_1\",\n",
    "    return_uncertainty=True,\n",
    "    n_mc_samples=10,\n",
    ")\n",
    "\n",
    "print(\"Uncertainty estimates:\")\n",
    "for unc in result_unc.uncertainty:\n",
    "    mean_std = np.mean(unc.std)\n",
    "    max_std = np.max(unc.std)\n",
    "    print(f\"  Task: {unc.task_name}\")\n",
    "    print(f\"    MC samples: {unc.n_samples}\")\n",
    "    print(f\"    Mean σ: {mean_std:.4f}, Max σ: {max_std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb1889a",
   "metadata": {},
   "source": [
    "### 1.4 Prediction with Latent Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "080d93e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent dimension: 8\n",
      "Latent vector:    ['1.002', '-0.913', '-0.774', '0.711', '0.319', '0.368', '-1.867', '1.154']\n"
     ]
    }
   ],
   "source": [
    "result_lat = pipeline.predict(\n",
    "    sequence,\n",
    "    protein_name=\"demo_protein_1\",\n",
    "    return_latent=True,\n",
    ")\n",
    "\n",
    "print(f\"Latent dimension: {len(result_lat.latent)}\")\n",
    "print(f\"Latent vector:    {[f'{v:.3f}' for v in result_lat.latent]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0876dd6",
   "metadata": {},
   "source": [
    "### 1.5 Batch Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bddc7ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 5\n",
      "\n",
      "  protein_1: len=30, cp[:3]=['0.358', '-0.209', '0.003'], mean_σ=0.0934 time=13.4ms\n",
      "  protein_2: len=20, cp[:3]=['-0.477', '-0.516', '-0.132'], mean_σ=0.1108 time=11.4ms\n",
      "  protein_3: len=20, cp[:3]=['-0.567', '-0.611', '-0.306'], mean_σ=0.0585 time=10.8ms\n",
      "  protein_4: len=20, cp[:3]=['0.151', '-0.568', '-0.100'], mean_σ=0.1105 time=9.6ms\n",
      "  protein_5: len=20, cp[:3]=['-0.147', '-0.371', '-0.238'], mean_σ=0.2633 time=10.4ms\n"
     ]
    }
   ],
   "source": [
    "sequences = [\n",
    "    \"MKFLILLFNILCLFPVLAADNHGVGPQGAS\",\n",
    "    \"ACDEFGHIKLMNPQRSTVWY\",\n",
    "    \"GGGGGGGGGGAAAAAAAAAA\",\n",
    "    \"MTEYKLVVVGAGGVGKSALT\",\n",
    "    \"FWKRHCQPLAGDELLHQRRL\",\n",
    "]\n",
    "names = [f\"protein_{i+1}\" for i in range(len(sequences))]\n",
    "\n",
    "batch_results = pipeline.predict_batch(\n",
    "    sequences,\n",
    "    protein_names=names,\n",
    "    return_uncertainty=True,\n",
    "    n_mc_samples=5,\n",
    ")\n",
    "\n",
    "print(f\"Batch size: {len(batch_results)}\")\n",
    "print()\n",
    "\n",
    "for res in batch_results:\n",
    "    cp_vals = res.predictions[0].values[:3]\n",
    "    unc_mean = np.mean(res.uncertainty[0].std) if res.uncertainty else None\n",
    "    print(\n",
    "        f\"  {res.protein_name}: \"\n",
    "        f\"len={res.sequence_length}, \"\n",
    "        f\"cp[:3]={[f'{v:.3f}' for v in cp_vals]}, \"\n",
    "        f\"mean_σ={unc_mean:.4f}\" if unc_mean else 'N/A',\n",
    "        f\"time={res.inference_time_ms:.1f}ms\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea75369",
   "metadata": {},
   "source": [
    "### 1.6 Health Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2885a0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  status: healthy\n",
      "  model_loaded: True\n",
      "  esm_loaded: True\n",
      "  uptime_seconds: 0.2\n",
      "  version: v1.0\n",
      "  device: cpu\n",
      "  checks: {'model_loaded': True, 'esm_loaded': True, 'checkpoint_exists': True}\n"
     ]
    }
   ],
   "source": [
    "health = pipeline.health_check()\n",
    "for key, value in health.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a42516",
   "metadata": {},
   "source": [
    "## 2. Checkpoint Compatibility\n",
    "\n",
    "The serving pipeline handles **four checkpoint formats** transparently:\n",
    "\n",
    "| Format | Source | `config` key contains: |\n",
    "|--------|--------|-----------------------|\n",
    "| Trainer | `Trainer.save_checkpoint()` | `TrainerConfig` |\n",
    "| Callback | `CheckpointCallback` | `TrainerConfig.__dict__` + `best_value`/`monitor` |\n",
    "| Pipeline | `InferencePipeline` / `ModelRegistry` | `ProToPhenConfig` |\n",
    "| Raw | `torch.save(model.state_dict(), ...)` | (no config) |\n",
    "\n",
    "When the config contains `TrainerConfig` fields (epochs, learning_rate, etc.)\n",
    "instead of `ProToPhenConfig` fields, the pipeline **automatically infers**\n",
    "the model architecture from the shapes of the state dict tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34ff058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from protophen.serving.pipeline import (\n",
    "    load_checkpoint,\n",
    "    build_model_from_checkpoint,\n",
    "    _is_trainer_config,\n",
    "    _infer_model_config_from_state_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c31f01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.pipeline\u001b[0m:\u001b[36mload_checkpoint\u001b[0m:\u001b[36m245\u001b[0m | \u001b[1mLoading checkpoint from C:\\Users\\adou0002\\AppData\\Local\\Temp\\protophen_deploy_f2qccnb8\\checkpoints\\trainer_best.pt\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.pipeline\u001b[0m:\u001b[36mload_checkpoint\u001b[0m:\u001b[36m272\u001b[0m | \u001b[1mCheckpoint 'config' appears to be TrainerConfig; inferring ProToPhenConfig from state dict shapes.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint keys: ['epoch', 'global_step', 'model_state_dict', 'optimiser_state_dict', 'config', 'best_val_loss', '_trainer_config', 'version', 'metrics']\n",
      "Epoch:           75\n",
      "Version:         epoch_75\n",
      "Metrics:         {'best_val_loss': 0.0312}\n",
      "TrainerConfig:   True\n"
     ]
    }
   ],
   "source": [
    "# Load the Trainer-format checkpoint\n",
    "ckpt = load_checkpoint(trainer_ckpt_path, device=\"cpu\")\n",
    "\n",
    "print(\"Checkpoint keys:\", list(ckpt.keys()))\n",
    "print(f\"Epoch:           {ckpt['epoch']}\")\n",
    "print(f\"Version:         {ckpt['version']}\")\n",
    "print(f\"Metrics:         {ckpt['metrics']}\")\n",
    "print(f\"TrainerConfig:   {'_trainer_config' in ckpt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "204b6f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is TrainerConfig dict? True\n",
      "Is model config dict?  False\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate the heuristic\n",
    "trainer_dict = asdict(trainer_config)\n",
    "model_dict = {\n",
    "    \"protein_embedding_dim\": 32,\n",
    "    \"encoder_hidden_dims\": [16],\n",
    "    \"encoder_output_dim\": 8,\n",
    "}\n",
    "\n",
    "print(f\"Is TrainerConfig dict? {_is_trainer_config(trainer_dict)}\")\n",
    "print(f\"Is model config dict?  {_is_trainer_config(model_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "485cf4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.pipeline\u001b[0m:\u001b[36m_infer_model_config_from_state_dict\u001b[0m:\u001b[36m203\u001b[0m | \u001b[1mInferred ProToPhenConfig from state dict: input=32, latent=8, cp_dim=10\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred protein_embedding_dim: 32\n",
      "Inferred encoder_output_dim:    8\n",
      "Inferred cell_painting_dim:     10\n",
      "Inferred predict_viability:     True\n",
      "Inferred encoder_hidden_dims:   [16]\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate config inference from state dict\n",
    "inferred_config = _infer_model_config_from_state_dict(model.state_dict())\n",
    "\n",
    "print(f\"Inferred protein_embedding_dim: {inferred_config.protein_embedding_dim}\")\n",
    "print(f\"Inferred encoder_output_dim:    {inferred_config.encoder_output_dim}\")\n",
    "print(f\"Inferred cell_painting_dim:     {inferred_config.cell_painting_dim}\")\n",
    "print(f\"Inferred predict_viability:     {inferred_config.predict_viability}\")\n",
    "print(f\"Inferred encoder_hidden_dims:   {inferred_config.encoder_hidden_dims}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07f2dbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.pipeline\u001b[0m:\u001b[36m_infer_model_config_from_state_dict\u001b[0m:\u001b[36m203\u001b[0m | \u001b[1mInferred ProToPhenConfig from state dict: input=32, latent=8, cp_dim=10\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.models.protophen\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m | \u001b[1mInitialised ProToPhenModel: 10,915 parameters, tasks=['cell_painting', 'viability']\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.pipeline\u001b[0m:\u001b[36mbuild_model_from_checkpoint\u001b[0m:\u001b[36m344\u001b[0m | \u001b[1mModel restored (epoch 75), 10,915 params on cpu\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored successfully (10,915 params)\n",
      "  cell_painting: torch.Size([2, 10])\n",
      "  viability: torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "# Build model from the Trainer checkpoint and verify it works\n",
    "restored_model = build_model_from_checkpoint(ckpt, device=\"cpu\")\n",
    "\n",
    "x = torch.randn(2, 32)\n",
    "with torch.no_grad():\n",
    "    outputs = restored_model(x)\n",
    "\n",
    "print(f\"Model restored successfully ({restored_model.n_parameters:,} params)\")\n",
    "for task, tensor in outputs.items():\n",
    "    print(f\"  {task}: {tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d005fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.pipeline\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m421\u001b[0m | \u001b[1mInferencePipeline initialised (device=cpu, checkpoint=None)\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.pipeline\u001b[0m:\u001b[36mload_checkpoint\u001b[0m:\u001b[36m245\u001b[0m | \u001b[1mLoading checkpoint from C:\\Users\\adou0002\\AppData\\Local\\Temp\\protophen_deploy_f2qccnb8\\checkpoints\\trainer_best.pt\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.pipeline\u001b[0m:\u001b[36mload_checkpoint\u001b[0m:\u001b[36m272\u001b[0m | \u001b[1mCheckpoint 'config' appears to be TrainerConfig; inferring ProToPhenConfig from state dict shapes.\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.pipeline\u001b[0m:\u001b[36m_infer_model_config_from_state_dict\u001b[0m:\u001b[36m203\u001b[0m | \u001b[1mInferred ProToPhenConfig from state dict: input=32, latent=8, cp_dim=10\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.models.protophen\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m | \u001b[1mInitialised ProToPhenModel: 10,915 parameters, tasks=['cell_painting', 'viability']\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.pipeline\u001b[0m:\u001b[36mbuild_model_from_checkpoint\u001b[0m:\u001b[36m344\u001b[0m | \u001b[1mModel restored (epoch 75), 10,915 params on cpu\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.pipeline\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m512\u001b[0m | \u001b[1mModel version 'epoch_75' loaded successfully\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline model version: epoch_75\n",
      "Trainer config available: True\n",
      "  learning_rate: 0.0001\n",
      "  optimiser:     adamw\n",
      "  tasks:         ['cell_painting', 'viability']\n",
      "Checkpoint metrics: {'best_val_loss': 0.0312}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.embeddings.fusion\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m423\u001b[0m | \u001b[1mInitialised EmbeddingFusion: method=concatenate\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 2 tasks, 5.3ms\n"
     ]
    }
   ],
   "source": [
    "# The pipeline can also load this checkpoint seamlessly\n",
    "pipeline2 = InferencePipeline(config=PipelineConfig(device=\"cpu\", use_fp16=False, include_physicochemical=False)) # Note: include_physicochemical defaults to True in production, but we have set it to False here to match our mock embedder's 32 dims (otherwise we'd get a matrix multiplication error)\n",
    "pipeline2.load_model(trainer_ckpt_path)\n",
    "pipeline2._esm_embedder = mock_esm\n",
    "\n",
    "# Trainer config is preserved for reproducibility\n",
    "print(f\"Pipeline model version: {pipeline2.model_version}\")\n",
    "print(f\"Trainer config available: {pipeline2.trainer_config is not None}\")\n",
    "if pipeline2.trainer_config:\n",
    "    tc = pipeline2.trainer_config\n",
    "    print(f\"  learning_rate: {tc['learning_rate']}\")\n",
    "    print(f\"  optimiser:     {tc['optimiser']}\")\n",
    "    print(f\"  tasks:         {tc['tasks']}\")\n",
    "\n",
    "print(f\"Checkpoint metrics: {pipeline2.checkpoint_metrics}\")\n",
    "\n",
    "# Predictions work normally\n",
    "result = pipeline2.predict(\"ACDEFGHIKL\")\n",
    "print(f\"Prediction: {len(result.predictions)} tasks, {result.inference_time_ms:.1f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83521f9",
   "metadata": {},
   "source": [
    "## 3. Model Registry\n",
    "\n",
    "The `ModelRegistry` provides filesystem-backed model versioning with\n",
    "support for staging, production promotion, rollback, and comparison.\n",
    "\n",
    "```bash\n",
    "model_registry/\n",
    "├── registry.json         ← version index\n",
    "├── v1/\n",
    "│   └── model.pt          ← copied checkpoint\n",
    "├── v2/\n",
    "│   └── model.pt\n",
    "└── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00e2cf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.registry\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m138\u001b[0m | \u001b[1mModelRegistry at C:\\Users\\adou0002\\AppData\\Local\\Temp\\protophen_deploy_f2qccnb8\\model_registry (0 versions)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelRegistry(dir=C:\\Users\\adou0002\\AppData\\Local\\Temp\\protophen_deploy_f2qccnb8\\model_registry, versions=0, production=none)\n"
     ]
    }
   ],
   "source": [
    "from protophen.serving.registry import ModelRegistry, RegistryConfig\n",
    "\n",
    "registry = ModelRegistry(\n",
    "    config=RegistryConfig(\n",
    "        registry_dir=str(REGISTRY_DIR),\n",
    "        max_versions=20,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(registry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1a8222",
   "metadata": {},
   "source": [
    "### 3.1 Register Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb8bf0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m254\u001b[0m | \u001b[1mRegistered model version 'v1.0' (stage=staging)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered: v1.0 (stage=staging)\n"
     ]
    }
   ],
   "source": [
    "# Register the pipeline-style checkpoint\n",
    "mv1 = registry.register(\n",
    "    checkpoint_path=pipeline_ckpt_path,\n",
    "    version=\"v1.0\",\n",
    "    description=\"Baseline model, cosine scheduler, 75 epochs\",\n",
    "    metrics={\"val_r2\": 0.72, \"val_mse\": 0.031, \"val_pearson\": 0.85},\n",
    "    tags=[\"baseline\", \"cosine\"],\n",
    ")\n",
    "\n",
    "print(f\"Registered: {mv1.version} (stage={mv1.stage})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74ac975a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.pipeline\u001b[0m:\u001b[36mload_checkpoint\u001b[0m:\u001b[36m245\u001b[0m | \u001b[1mLoading checkpoint from C:\\Users\\adou0002\\AppData\\Local\\Temp\\protophen_deploy_f2qccnb8\\checkpoints\\trainer_best.pt\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.pipeline\u001b[0m:\u001b[36mload_checkpoint\u001b[0m:\u001b[36m272\u001b[0m | \u001b[1mCheckpoint 'config' appears to be TrainerConfig; inferring ProToPhenConfig from state dict shapes.\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.registry\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m254\u001b[0m | \u001b[1mRegistered model version 'v2.0' (stage=staging)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered: v2.0 (stage=staging)\n",
      "  Epoch:           75\n",
      "  Metrics:         {'best_val_loss': 0.0312}\n",
      "  TrainerConfig:   True\n",
      "  Auto-description: Trainer checkpoint at epoch 75, best_val_loss=0.0312\n"
     ]
    }
   ],
   "source": [
    "# Register from a Trainer checkpoint\n",
    "mv2 = registry.register_from_trainer_checkpoint(\n",
    "    checkpoint_path=trainer_ckpt_path,\n",
    "    version=\"v2.0\",\n",
    "    tags=[\"improved\", \"longer_training\"],\n",
    ")\n",
    "\n",
    "print(f\"Registered: {mv2.version} (stage={mv2.stage})\")\n",
    "print(f\"  Epoch:           {mv2.epoch}\")\n",
    "print(f\"  Metrics:         {mv2.metrics}\")\n",
    "print(f\"  TrainerConfig:   {mv2.trainer_config is not None}\")\n",
    "print(f\"  Auto-description: {mv2.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00123bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  v2.0 | stage=staging | metrics={'best_val_loss': 0.0312}\n",
      "  v1.0 | stage=staging | metrics={'val_r2': 0.72, 'val_mse': 0.031, 'val_pearson': 0.85}\n"
     ]
    }
   ],
   "source": [
    "# List all versions\n",
    "for v in registry.list_versions():\n",
    "    print(f\"  {v.version} | stage={v.stage} | metrics={v.metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4265e39a",
   "metadata": {},
   "source": [
    "### 3.2 Promote to Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "803f1bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.registry\u001b[0m:\u001b[36mset_stage\u001b[0m:\u001b[36m382\u001b[0m | \u001b[1mVersion 'v1.0' → stage=production\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Production checkpoint: C:\\Users\\adou0002\\AppData\\Local\\Temp\\protophen_deploy_f2qccnb8\\model_registry\\v1.0\\model.pt\n",
      "v1.0 stage: production\n"
     ]
    }
   ],
   "source": [
    "registry.set_stage(\"v1.0\", \"production\")\n",
    "\n",
    "print(f\"Production checkpoint: {registry.get_production_checkpoint()}\")\n",
    "print(f\"v1.0 stage: {registry.get_version('v1.0').stage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23f3bb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.registry\u001b[0m:\u001b[36mset_stage\u001b[0m:\u001b[36m377\u001b[0m | \u001b[1mVersion 'v1.0' archived (replaced by 'v2.0')\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.registry\u001b[0m:\u001b[36mset_stage\u001b[0m:\u001b[36m382\u001b[0m | \u001b[1mVersion 'v2.0' → stage=production\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1.0 stage: archived\n",
      "v2.0 stage: production\n",
      "Production: C:\\Users\\adou0002\\AppData\\Local\\Temp\\protophen_deploy_f2qccnb8\\model_registry\\v2.0\\model.pt\n"
     ]
    }
   ],
   "source": [
    "# Promote v2.0 → automatically archives v1.0\n",
    "registry.set_stage(\"v2.0\", \"production\")\n",
    "\n",
    "print(f\"v1.0 stage: {registry.get_version('v1.0').stage}\")  # archived\n",
    "print(f\"v2.0 stage: {registry.get_version('v2.0').stage}\")  # production\n",
    "print(f\"Production: {registry.get_production_checkpoint()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a47be4",
   "metadata": {},
   "source": [
    "### 3.3 Compare Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb392ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing v1.0 vs v2.0:\n",
      "  best_val_loss: None → 0.0312 (Δ=N/A)\n",
      "  val_mse: 0.031 → None (Δ=N/A)\n",
      "  val_pearson: 0.85 → None (Δ=N/A)\n",
      "  val_r2: 0.72 → None (Δ=N/A)\n"
     ]
    }
   ],
   "source": [
    "comparison = registry.compare_versions(\"v1.0\", \"v2.0\")\n",
    "\n",
    "print(f\"Comparing {comparison['version_a']} vs {comparison['version_b']}:\")\n",
    "for metric, data in comparison[\"metrics\"].items():\n",
    "    delta = data.get(\"delta\")\n",
    "    delta_str = f\"{delta:+.4f}\" if delta is not None else \"N/A\"\n",
    "    print(f\"  {metric}: {data.get('v1.0', 'N/A')} → {data.get('v2.0', 'N/A')} (Δ={delta_str})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c0cf1b",
   "metadata": {},
   "source": [
    "### 3.4 Rollback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44cb2550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.registry\u001b[0m:\u001b[36mset_stage\u001b[0m:\u001b[36m377\u001b[0m | \u001b[1mVersion 'v2.0' archived (replaced by 'v1.0')\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.registry\u001b[0m:\u001b[36mset_stage\u001b[0m:\u001b[36m382\u001b[0m | \u001b[1mVersion 'v1.0' → stage=production\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.registry\u001b[0m:\u001b[36mrollback\u001b[0m:\u001b[36m465\u001b[0m | \u001b[1mRolled back to version 'v1.0'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolled back to: v1.0 (stage=production)\n",
      "Production checkpoint: C:\\Users\\adou0002\\AppData\\Local\\Temp\\protophen_deploy_f2qccnb8\\model_registry\\v1.0\\model.pt\n"
     ]
    }
   ],
   "source": [
    "# Rollback to the most recently archived version (v1.0)\n",
    "rolled_back = registry.rollback()\n",
    "\n",
    "print(f\"Rolled back to: {rolled_back.version} (stage={rolled_back.stage})\")\n",
    "print(f\"Production checkpoint: {registry.get_production_checkpoint()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f5860a",
   "metadata": {},
   "source": [
    "### 3.5 Best Version Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45b1da34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.registry\u001b[0m:\u001b[36mset_stage\u001b[0m:\u001b[36m377\u001b[0m | \u001b[1mVersion 'v1.0' archived (replaced by 'v2.0')\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.registry\u001b[0m:\u001b[36mset_stage\u001b[0m:\u001b[36m382\u001b[0m | \u001b[1mVersion 'v2.0' → stage=production\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best by val_r2: v1.0 (val_r2=0.72)\n"
     ]
    }
   ],
   "source": [
    "# Re-promote v2.0 so both are accessible\n",
    "registry.set_stage(\"v2.0\", \"production\")\n",
    "\n",
    "best = registry.get_best_version(\"val_r2\", higher_is_better=True)\n",
    "print(f\"Best by val_r2: {best.version} (val_r2={best.metrics.get('val_r2')})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a062c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  registry_dir: C:\\Users\\adou0002\\AppData\\Local\\Temp\\protophen_deploy_f2qccnb8\\model_registry\n",
      "  total_versions: 2\n",
      "  stages: {'archived': 1, 'production': 1}\n",
      "  production_version: v2.0\n",
      "  latest_version: v2.0\n"
     ]
    }
   ],
   "source": [
    "# Registry summary\n",
    "summary = registry.summary()\n",
    "for key, value in summary.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7917c9",
   "metadata": {},
   "source": [
    "### 3.6 Load Production Model into Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817f691c",
   "metadata": {},
   "source": [
    "**This is the typical deployment pattern:**\n",
    " 1. Registry resolves the production checkpoint\n",
    " 2. Pipeline loads it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1850c2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.pipeline\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m421\u001b[0m | \u001b[1mInferencePipeline initialised (device=cpu, checkpoint=C:\\Users\\adou0002\\AppData\\Local\\Temp\\protophen_deploy_f2qccnb8\\model_registry\\v2.0\\model.pt)\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.pipeline\u001b[0m:\u001b[36mload_checkpoint\u001b[0m:\u001b[36m245\u001b[0m | \u001b[1mLoading checkpoint from C:\\Users\\adou0002\\AppData\\Local\\Temp\\protophen_deploy_f2qccnb8\\model_registry\\v2.0\\model.pt\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.pipeline\u001b[0m:\u001b[36mload_checkpoint\u001b[0m:\u001b[36m272\u001b[0m | \u001b[1mCheckpoint 'config' appears to be TrainerConfig; inferring ProToPhenConfig from state dict shapes.\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.pipeline\u001b[0m:\u001b[36m_infer_model_config_from_state_dict\u001b[0m:\u001b[36m203\u001b[0m | \u001b[1mInferred ProToPhenConfig from state dict: input=32, latent=8, cp_dim=10\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.models.protophen\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m | \u001b[1mInitialised ProToPhenModel: 10,915 parameters, tasks=['cell_painting', 'viability']\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.pipeline\u001b[0m:\u001b[36mbuild_model_from_checkpoint\u001b[0m:\u001b[36m344\u001b[0m | \u001b[1mModel restored (epoch 75), 10,915 params on cpu\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.pipeline\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m512\u001b[0m | \u001b[1mModel version 'epoch_75' loaded successfully\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.embeddings.fusion\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m423\u001b[0m | \u001b[1mInitialised EmbeddingFusion: method=concatenate\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Production model prediction: 2 tasks\n"
     ]
    }
   ],
   "source": [
    "# Resolve checkpoint for production model from registry\n",
    "prod_path = registry.get_production_checkpoint()\n",
    "\n",
    "# Load pipeline and mock embedder\n",
    "prod_pipeline = InferencePipeline(\n",
    "    checkpoint_path=prod_path,\n",
    "    config=PipelineConfig(device=\"cpu\", use_fp16=False, include_physicochemical=False), # Note: include_physicochemical defaults to True in production, but we have set it to False here to match our mock embedder's 32 dims (otherwise we'd get a matrix multiplication error)\n",
    ")\n",
    "prod_pipeline._esm_embedder = mock_esm\n",
    "\n",
    "# Perform inference with the production model\n",
    "result = prod_pipeline.predict(\"MKFLILLFNILCLFPVLAADNHGVGPQGAS\")\n",
    "print(f\"Production model prediction: {len(result.predictions)} tasks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32b4de1",
   "metadata": {},
   "source": [
    "## 4. Monitoring & Drift Detection\n",
    "\n",
    "The `PredictionMonitor` tracks latency, throughput, and prediction\n",
    "distribution statistics.\n",
    "\n",
    "The `DriftDetector` uses the Kolmogorov-Smirnov test to flag distribution shift relative to a reference (typically the training/validation set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b045019d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m245\u001b[0m | \u001b[1mPredictionMonitor initialised\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from protophen.serving.monitoring import (\n",
    "    PredictionMonitor,\n",
    "    MonitoringConfig,\n",
    "    DriftDetector,\n",
    ")\n",
    "\n",
    "monitor = PredictionMonitor(\n",
    "    config=MonitoringConfig(\n",
    "        window_size=500,\n",
    "        enable_drift_detection=True,\n",
    "        drift_window_size=100,\n",
    "        drift_significance=0.05,\n",
    "        log_predictions=False,  # quiet for notebook\n",
    "        track_regression_metrics=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d4083c",
   "metadata": {},
   "source": [
    "### 4.1 Record Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f96a4b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-18 16:38:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m533\u001b[0m | \u001b[1mDrift reference auto-set for 'cell_painting' from first 100 observations\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 200 requests:\n",
      "  Total requests:  200\n",
      "  Total errors:    0\n",
      "  Throughput:      12500.0 req/s\n",
      "  Latency p50:     15.1 ms\n",
      "  Latency p99:     21.6 ms\n"
     ]
    }
   ],
   "source": [
    "# Simulate 200 prediction requests\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "for i in range(200):\n",
    "    pred = rng.standard_normal(10).astype(np.float32)\n",
    "    monitor.record_request(\n",
    "        latency_ms=15.0 + rng.standard_normal() * 3.0,\n",
    "        sequence_length=100 + rng.integers(0, 200),\n",
    "        predictions={\"cell_painting\": pred},\n",
    "        protein_id=f\"prot_{i:04d}\",\n",
    "    )\n",
    "\n",
    "print(\"After 200 requests:\")\n",
    "summary = monitor.summary()\n",
    "print(f\"  Total requests:  {summary['total_requests']}\")\n",
    "print(f\"  Total errors:    {summary['total_errors']}\")\n",
    "print(f\"  Throughput:      {summary['throughput_rps']:.1f} req/s\")\n",
    "if \"latency_ms\" in summary:\n",
    "    lat = summary[\"latency_ms\"]\n",
    "    print(f\"  Latency p50:     {lat['p50']:.1f} ms\")\n",
    "    print(f\"  Latency p99:     {lat['p99']:.1f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3112d7",
   "metadata": {},
   "source": [
    "### 4.2 Drift Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f1bda6",
   "metadata": {},
   "source": [
    "The drift detector auto-sets its reference from the first window_size observations, then compares subsequent windows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e727c66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: cell_painting\n",
      "  drift_detected: False\n",
      "  p_value: 0.368188\n",
      "  reference_set: True\n",
      "  current_observations: 100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "drift_report = summary.get(\"drift\", {})\n",
    "for task, info in drift_report.items():\n",
    "    print(f\"Task: {task}\")\n",
    "    for key, value in info.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5202cd",
   "metadata": {},
   "source": [
    "### 4.3 Explicit Reference from Trainer Predictions\n",
    "\n",
    "In production, you'd typically set the reference from your validation set:\n",
    "\n",
    "```python\n",
    "    trainer_output = trainer.predict(val_loader, return_targets=True)\n",
    "\n",
    "    monitor._drift_detector.set_reference_from_trainer(trainer_output)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfb87b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference set:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=3.1370e-02 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=1.4501e-02 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=6.2610e-03 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=2.5229e-03 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=9.4793e-04 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=3.3175e-04 < 0.05\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  {'cell_painting': {'drift_detected': False, 'p_value': 1.0, 'reference_set': True, 'current_observations': 0}}\n",
      "\n",
      "After same-distribution observations:\n",
      "  Drift detected: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=1.0802e-04 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=3.2685e-05 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=9.1779e-06 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=2.3880e-06 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=2.3880e-06 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=5.7478e-07 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=1.2776e-07 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=2.6171e-08 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=4.9303e-09 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=8.5214e-10 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=1.3477e-10 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=1.9445e-11 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=2.5517e-12 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=3.0342e-13 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=3.2563e-14 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=3.1398e-15 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=2.7063e-16 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=2.0732e-17 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=1.4022e-18 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=8.3102e-20 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=4.2777e-21 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=4.1885e-22 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=1.6415e-23 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=5.4040e-25 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=1.4691e-26 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=3.2284e-28 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=5.5832e-30 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=7.3360e-32 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=6.9847e-34 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=4.5069e-36 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=1.7829e-38 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=3.6739e-41 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=2.9278e-44 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=4.6958e-48 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=1.4839e-53 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=1.4839e-53 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=1.4839e-53 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=1.4839e-53 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=1.4839e-53 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=1.4839e-53 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=1.4839e-53 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=1.4839e-53 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=1.4839e-53 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=1.4839e-53 < 0.05\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36madd_observation\u001b[0m:\u001b[36m549\u001b[0m | \u001b[33m\u001b[1mDrift detected for task 'cell_painting': KS p=1.4839e-53 < 0.05\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After shifted observations:\n",
      "  Drift detected: True\n",
      "  KS p-value:     0.00e+00\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate with synthetic data\n",
    "detector = DriftDetector(window_size=50, significance=0.05)\n",
    "\n",
    "# Set reference from \"training\" predictions\n",
    "ref_predictions = rng.standard_normal((200, 10))\n",
    "detector.set_reference_from_trainer({\n",
    "    \"cell_painting_predictions\": ref_predictions,\n",
    "})\n",
    "\n",
    "print(\"Reference set:\")\n",
    "print(f\"  {detector.report()}\")\n",
    "\n",
    "# Add observations from the same distribution (no drift expected)\n",
    "for _ in range(60):\n",
    "    detector.add_observation(\"cell_painting\", rng.standard_normal(10))\n",
    "\n",
    "print(f\"\\nAfter same-distribution observations:\")\n",
    "print(f\"  Drift detected: {detector.report()['cell_painting']['drift_detected']}\")\n",
    "\n",
    "# Now shift the distribution\n",
    "for _ in range(60):\n",
    "    detector.add_observation(\"cell_painting\", rng.standard_normal(10) + 5.0)\n",
    "\n",
    "print(f\"\\nAfter shifted observations:\")\n",
    "report = detector.report()[\"cell_painting\"]\n",
    "print(f\"  Drift detected: {report['drift_detected']}\")\n",
    "print(f\"  KS p-value:     {report['p_value']:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee7d531",
   "metadata": {},
   "source": [
    "## 5. Feedback & Quality Tracking\n",
    "\n",
    "When you have generated wet-lab results, they can be fed back through the monitoring\n",
    "system to track prediction quality over time.\n",
    "\n",
    "The `PredictionQualityTracker` reuses the same regression metrics from `protophen.training.metrics` so that training and production evaluation are consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b575c51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality pairs stored: 20\n",
      "\n",
      "Prediction quality metrics (from training.metrics):\n",
      "  quality_cosine_similarity: 0.9947\n",
      "  quality_mae: 0.0778\n",
      "  quality_mse: 0.0104\n",
      "  quality_pearson: 0.9947\n",
      "  quality_r2: 0.9908\n",
      "  quality_rmse: 0.1019\n"
     ]
    }
   ],
   "source": [
    "from protophen.serving.monitoring import PredictionQualityTracker\n",
    "\n",
    "tracker = PredictionQualityTracker(window_size=200)\n",
    "\n",
    "# Simulate feedback: predictions with small noise\n",
    "for i in range(20):\n",
    "    true_phenotype = rng.standard_normal(10).astype(np.float32)\n",
    "    predicted_phenotype = true_phenotype + rng.standard_normal(10).astype(np.float32) * 0.1\n",
    "\n",
    "    tracker.add(f\"prot_{i:04d}\", predicted_phenotype, true_phenotype)\n",
    "\n",
    "print(f\"Quality pairs stored: {tracker.n_pairs}\")\n",
    "\n",
    "metrics = tracker.compute_metrics()\n",
    "print(\"\\nPrediction quality metrics (from training.metrics):\")\n",
    "for name, value in sorted(metrics.items()):\n",
    "    print(f\"  {name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c50a17",
   "metadata": {},
   "source": [
    "### 5.1 Monitor-Integrated Feedback\n",
    "\n",
    "In the full API workflow, the monitor automatically matches cached\n",
    "predictions with incoming feedback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f33cdb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m245\u001b[0m | \u001b[1mPredictionMonitor initialised\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total requests:  10\n",
      "Total feedback:  10\n",
      "\n",
      "Prediction quality (10 pairs):\n",
      "  quality_cosine_similarity: 0.9990\n",
      "  quality_mae: 0.0395\n",
      "  quality_mse: 0.0024\n",
      "  quality_pearson: 0.9990\n",
      "  quality_r2: 0.9982\n",
      "  quality_rmse: 0.0492\n"
     ]
    }
   ],
   "source": [
    "# Create a fresh monitor\n",
    "monitor2 = PredictionMonitor(\n",
    "    config=MonitoringConfig(\n",
    "        enable_drift_detection=False,\n",
    "        log_predictions=False,\n",
    "        track_regression_metrics=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Simulate: predict, then receive feedback\n",
    "for i in range(10):\n",
    "    pred = rng.standard_normal(10).astype(np.float32)\n",
    "    obs = pred + rng.standard_normal(10).astype(np.float32) * 0.05\n",
    "\n",
    "    # Step 1: Record prediction (caches prediction by protein_id)\n",
    "    monitor2.record_request(\n",
    "        latency_ms=12.0,\n",
    "        sequence_length=150,\n",
    "        predictions={\"cell_painting\": pred},\n",
    "        protein_id=f\"fb_prot_{i}\",\n",
    "    )\n",
    "\n",
    "    # Step 2: Feed observation back (monitor matches to cached prediction)\n",
    "    monitor2.record_feedback(\n",
    "        protein_id=f\"fb_prot_{i}\",\n",
    "        observation=obs,\n",
    "    )\n",
    "\n",
    "summary2 = monitor2.summary()\n",
    "print(f\"Total requests:  {summary2['total_requests']}\")\n",
    "print(f\"Total feedback:  {summary2['total_feedback']}\")\n",
    "\n",
    "if \"prediction_quality\" in summary2:\n",
    "    pq = summary2[\"prediction_quality\"]\n",
    "    print(f\"\\nPrediction quality ({pq['n_pairs']} pairs):\")\n",
    "    for name, value in sorted(pq.items()):\n",
    "        if name != \"n_pairs\":\n",
    "            print(f\"  {name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731de526",
   "metadata": {},
   "source": [
    "## 6. REST API\n",
    "\n",
    "The `create_app()` factory produces a FastAPI application with\n",
    "endpoints for prediction, health checks, monitoring, and feedback.\n",
    "\n",
    "### Endpoints\n",
    "\n",
    "| Method | Path | Description |\n",
    "|--------|------|-------------|\n",
    "| `POST` | `/predict` | Single protein prediction |\n",
    "| `POST` | `/predict/batch` | Batch prediction (up to 1000) |\n",
    "| `POST` | `/feedback` | Active-learning feedback ingestion |\n",
    "| `GET` | `/health` | Readiness/liveness probe |\n",
    "| `GET` | `/model/info` | Model metadata |\n",
    "| `GET` | `/metrics` | Monitoring summary (JSON) |\n",
    "| `GET` | `/metrics/prometheus` | Prometheus-formatted metrics |\n",
    "\n",
    "### 6.1 Launch the Server (CLI)\n",
    "\n",
    "```bash\n",
    "# From a checkpoint:\n",
    "python scripts/serve.py --checkpoint checkpoints/best.pt\n",
    "\n",
    "# From the model registry:\n",
    "python scripts/serve.py --registry ./model_registry\n",
    "\n",
    "# With full config:\n",
    "python scripts/serve.py \\\n",
    "    --checkpoint checkpoints/best.pt \\\n",
    "    --config configs/deployment.yaml \\\n",
    "    --host 0.0.0.0 --port 8000 \\\n",
    "    --device cuda\n",
    "```\n",
    "\n",
    "### 6.2 In-Process Testing with httpx\n",
    "\n",
    "For notebooks and tests, we can use FastAPI's `TestClient` to\n",
    "exercise the API without starting a real server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b08b6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from fastapi.testclient import TestClient\n",
    "    from protophen.serving.api import create_app\n",
    "\n",
    "    _FASTAPI_AVAILABLE = True\n",
    "except ImportError:\n",
    "    _FASTAPI_AVAILABLE = False\n",
    "    print(\"FastAPI not installed — skipping API examples.\")\n",
    "    print(\"Install with: pip install 'protophen[serving]'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06a9f6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.api\u001b[0m:\u001b[36mlifespan\u001b[0m:\u001b[36m144\u001b[0m | \u001b[1mProToPhen API starting up\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.pipeline\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m421\u001b[0m | \u001b[1mInferencePipeline initialised (device=cpu, checkpoint=C:\\Users\\adou0002\\AppData\\Local\\Temp\\protophen_deploy_f2qccnb8\\checkpoints\\pipeline_v1.pt)\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.pipeline\u001b[0m:\u001b[36mload_checkpoint\u001b[0m:\u001b[36m245\u001b[0m | \u001b[1mLoading checkpoint from C:\\Users\\adou0002\\AppData\\Local\\Temp\\protophen_deploy_f2qccnb8\\checkpoints\\pipeline_v1.pt\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.models.protophen\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m | \u001b[1mInitialised ProToPhenModel: 10,915 parameters, tasks=['cell_painting', 'viability']\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.pipeline\u001b[0m:\u001b[36mbuild_model_from_checkpoint\u001b[0m:\u001b[36m344\u001b[0m | \u001b[1mModel restored (epoch 75), 10,915 params on cpu\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.pipeline\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m512\u001b[0m | \u001b[1mModel version 'v1.0' loaded successfully\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.monitoring\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m245\u001b[0m | \u001b[1mPredictionMonitor initialised\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.registry\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m138\u001b[0m | \u001b[1mModelRegistry at C:\\Users\\adou0002\\AppData\\Local\\Temp\\protophen_deploy_f2qccnb8\\model_registry (2 versions)\u001b[0m\n",
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.api\u001b[0m:\u001b[36mlifespan\u001b[0m:\u001b[36m170\u001b[0m | \u001b[1mProToPhen API ready\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestClient ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.api\u001b[0m:\u001b[36mlifespan\u001b[0m:\u001b[36m172\u001b[0m | \u001b[1mProToPhen API shutting down\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if _FASTAPI_AVAILABLE:\n",
    "    # Create the app with our demo checkpoint\n",
    "    app = create_app(\n",
    "        checkpoint_path=str(pipeline_ckpt_path),\n",
    "        pipeline_config=PipelineConfig(\n",
    "            device=\"cpu\",\n",
    "            use_fp16=False,\n",
    "            include_physicochemical=False,\n",
    "        ),\n",
    "        monitoring_config=MonitoringConfig(\n",
    "            enable_drift_detection=False,\n",
    "            log_predictions=False,\n",
    "        ),\n",
    "        registry_dir=str(REGISTRY_DIR),\n",
    "        feedback_dir=str(FEEDBACK_DIR),\n",
    "    )\n",
    "\n",
    "    # Enter content to trigger Lifespan (loads model)\n",
    "    client = TestClient(app)\n",
    "    client.__enter__()\n",
    "\n",
    "    # Inject mock ESM into the loaded pipeline\n",
    "    state = app.state._protophen\n",
    "    if state.pipeline is not None:\n",
    "        state.pipeline._esm_embedder = mock_esm\n",
    "\n",
    "    print(\"TestClient ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10eb118",
   "metadata": {},
   "source": [
    "### 6.3 Health Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8fd8fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 200\n",
      "  status: healthy\n",
      "  model_loaded: True\n",
      "  esm_loaded: True\n",
      "  uptime_seconds: 0.0\n",
      "  version: v1.0\n",
      "  device: cpu\n",
      "  checks: {'model_loaded': True, 'esm_loaded': True, 'checkpoint_exists': True}\n"
     ]
    }
   ],
   "source": [
    "if _FASTAPI_AVAILABLE:\n",
    "    resp = client.get(\"/health\")\n",
    "    print(f\"Status: {resp.status_code}\")\n",
    "    health = resp.json()\n",
    "    for key, value in health.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adf6e70",
   "metadata": {},
   "source": [
    "### 6.4 Model Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "931ba1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 200\n",
      "  model_version: v1.0\n",
      "  model_name: ProToPhen\n",
      "  tasks: {'cell_painting': 10, 'viability': 1}\n",
      "  latent_dim: 8\n",
      "  protein_embedding_dim: 32\n",
      "  n_parameters: 10915\n",
      "  n_trainable_parameters: 10915\n",
      "  encoder_hidden_dims: [16]\n",
      "  decoder_hidden_dims: [16]\n",
      "  esm_model: esm2_t33_650M_UR50D\n",
      "  fusion_method: concatenate\n",
      "  device: cpu\n",
      "  loaded_at: 2026-02-18T05:38:24.637569+00:00\n"
     ]
    }
   ],
   "source": [
    "if _FASTAPI_AVAILABLE:\n",
    "    resp = client.get(\"/model/info\")\n",
    "    print(f\"Status: {resp.status_code}\")\n",
    "    info = resp.json()\n",
    "    for key, value in info.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728d8b9c",
   "metadata": {},
   "source": [
    "### 6.5 Single Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7c552e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.embeddings.fusion\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m423\u001b[0m | \u001b[1mInitialised EmbeddingFusion: method=concatenate\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 200\n",
      "Protein:       demo_protein\n",
      "Sequence len:  30\n",
      "Inference:     18.5 ms\n",
      "Latent dim:    8\n",
      "N predictions: 2\n",
      "N uncertainty: 2\n"
     ]
    }
   ],
   "source": [
    "if _FASTAPI_AVAILABLE:\n",
    "    resp = client.post(\"/predict\", json={\n",
    "        \"protein\": {\n",
    "            \"sequence\": \"MKFLILLFNILCLFPVLAADNHGVGPQGAS\",\n",
    "            \"name\": \"demo_protein\",\n",
    "        },\n",
    "        \"return_latent\": True,\n",
    "        \"return_uncertainty\": True,\n",
    "        \"n_uncertainty_samples\": 5,\n",
    "    })\n",
    "\n",
    "    print(f\"Status: {resp.status_code}\")\n",
    "    data = resp.json()\n",
    "    print(f\"Protein:       {data['protein_name']}\")\n",
    "    print(f\"Sequence len:  {data['sequence_length']}\")\n",
    "    print(f\"Inference:     {data['inference_time_ms']:.1f} ms\")\n",
    "    print(f\"Latent dim:    {len(data['latent'])}\")\n",
    "    print(f\"N predictions: {len(data['predictions'])}\")\n",
    "    print(f\"N uncertainty: {len(data['uncertainty'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c94aa4",
   "metadata": {},
   "source": [
    "### 6.6 Batch Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a3c77c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 200\n",
      "N proteins:     3\n",
      "Total time:     7.5 ms\n",
      "Model version:  v1.0\n",
      "  prot_a: len=30, tasks=2\n",
      "  prot_b: len=20, tasks=2\n",
      "  prot_c: len=20, tasks=2\n"
     ]
    }
   ],
   "source": [
    "if _FASTAPI_AVAILABLE:\n",
    "    resp = client.post(\"/predict/batch\", json={\n",
    "        \"proteins\": [\n",
    "            {\"sequence\": \"MKFLILLFNILCLFPVLAADNHGVGPQGAS\", \"name\": \"prot_a\"},\n",
    "            {\"sequence\": \"ACDEFGHIKLMNPQRSTVWY\", \"name\": \"prot_b\"},\n",
    "            {\"sequence\": \"MTEYKLVVVGAGGVGKSALT\", \"name\": \"prot_c\"},\n",
    "        ],\n",
    "        \"return_uncertainty\": False,\n",
    "    })\n",
    "\n",
    "    print(f\"Status: {resp.status_code}\")\n",
    "    data = resp.json()\n",
    "    print(f\"N proteins:     {data['n_proteins']}\")\n",
    "    print(f\"Total time:     {data['total_inference_time_ms']:.1f} ms\")\n",
    "    print(f\"Model version:  {data['model_version']}\")\n",
    "    for r in data[\"results\"]:\n",
    "        print(f\"  {r['protein_name']}: len={r['sequence_length']}, \"\n",
    "              f\"tasks={len(r['predictions'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d58be8",
   "metadata": {},
   "source": [
    "### 6.7 Feedback Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8986d409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-18 16:38:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mprotophen.serving.api\u001b[0m:\u001b[36mfeedback\u001b[0m:\u001b[36m357\u001b[0m | \u001b[1mFeedback received for protein 'demo_protein': 10 features (total stored: 1)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 200\n",
      "  status: accepted\n",
      "  protein_id: demo_protein\n",
      "  message: Feedback stored successfully (1 total entries).\n",
      "  reselection_triggered: False\n",
      "  next_candidates: None\n"
     ]
    }
   ],
   "source": [
    "if _FASTAPI_AVAILABLE:\n",
    "    resp = client.post(\"/feedback\", json={\n",
    "        \"protein_id\": \"demo_protein\",\n",
    "        \"sequence\": \"MKFLILLFNILCLFPVLAADNHGVGPQGAS\",\n",
    "        \"observed_features\": [0.1] * 10,\n",
    "        \"plate_id\": \"plate_001\",\n",
    "        \"well_id\": \"A02\",\n",
    "        \"cell_count\": 1500,\n",
    "        \"trigger_reselection\": False,\n",
    "    })\n",
    "\n",
    "    print(f\"Status: {resp.status_code}\")\n",
    "    fb = resp.json()\n",
    "    for key, value in fb.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20a020c",
   "metadata": {},
   "source": [
    "### 6.8 Monitoring Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a049359c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 200\n",
      "  total_requests: 4\n",
      "  total_errors: 0\n",
      "  total_feedback: 0\n",
      "  error_rate: 0.0\n",
      "  throughput_rps: 32.0\n",
      "  uptime_seconds: 0.1\n",
      "  latency_ms:\n",
      "    mean: 6.45\n",
      "    p50: 2.71\n",
      "    p95: 16.22\n",
      "    p99: 18.03\n",
      "    max: 18.48\n",
      "  prediction_norm:\n",
      "    mean: 0.784\n",
      "    std: 0.2028\n"
     ]
    }
   ],
   "source": [
    "if _FASTAPI_AVAILABLE:\n",
    "    resp = client.get(\"/metrics\")\n",
    "    print(f\"Status: {resp.status_code}\")\n",
    "    metrics = resp.json()\n",
    "    for key, value in metrics.items():\n",
    "        if isinstance(value, dict):\n",
    "            print(f\"  {key}:\")\n",
    "            for k2, v2 in value.items():\n",
    "                print(f\"    {k2}: {v2}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db06cc4",
   "metadata": {},
   "source": [
    "### 6.9 Input Validation\n",
    "\n",
    "The API rejects invalid sequences with clear error messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "198a6e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid chars → 422: [{'type': 'value_error', 'loc': ['body', 'protein', 'sequence'], 'msg': \"Value error, Sequence contains invalid characters: {'3', '1', '2'}. Allowed: ACDEFGHIKLMNPQRSTVWY\", 'input': 'MKFLIL123', 'ctx': {'error': {}}}]\n",
      "Empty seq     → 422\n",
      "Empty batch   → 422\n"
     ]
    }
   ],
   "source": [
    "if _FASTAPI_AVAILABLE:\n",
    "    # Invalid characters\n",
    "    resp = client.post(\"/predict\", json={\n",
    "        \"protein\": {\"sequence\": \"MKFLIL123\"},\n",
    "    })\n",
    "    print(f\"Invalid chars → {resp.status_code}: {resp.json()['detail']}\")\n",
    "\n",
    "    # Empty sequence\n",
    "    resp = client.post(\"/predict\", json={\n",
    "        \"protein\": {\"sequence\": \"   \"},\n",
    "    })\n",
    "    print(f\"Empty seq     → {resp.status_code}\")\n",
    "\n",
    "    # Empty batch\n",
    "    resp = client.post(\"/predict/batch\", json={\n",
    "        \"proteins\": [],\n",
    "    })\n",
    "    print(f\"Empty batch   → {resp.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbe662a",
   "metadata": {},
   "source": [
    "## 7. Docker Deployment\n",
    "\n",
    "ProToPhen includes Docker configurations for containerised deployment.\n",
    "\n",
    "### File Structure\n",
    "\n",
    "```bash\n",
    "docker/\n",
    "├── Dockerfile           # CPU-only image\n",
    "├── Dockerfile.gpu       # CUDA-enabled image\n",
    "└── docker-compose.yml   # Service orchestration\n",
    "```\n",
    "\n",
    "### 7.1 Build & Run (CPU)\n",
    "\n",
    "```bash\n",
    "# Build\n",
    "docker build -t protophen:latest -f docker/Dockerfile .\n",
    "\n",
    "# Run with a checkpoint mounted from the host\n",
    "docker run -p 8000:8000 \\\n",
    "    -v ./checkpoints:/app/checkpoints:ro \\\n",
    "    -v ./model_registry:/app/model_registry \\\n",
    "    protophen:latest \\\n",
    "    python scripts/serve.py \\\n",
    "        --checkpoint /app/checkpoints/best.pt \\\n",
    "        --config /app/configs/deployment.yaml\n",
    "```\n",
    "\n",
    "### 7.2 Build & Run (GPU)\n",
    "\n",
    "```bash\n",
    "docker build -t protophen:gpu -f docker/Dockerfile.gpu .\n",
    "\n",
    "docker run --gpus all -p 8000:8000 \\\n",
    "    -v ./checkpoints:/app/checkpoints:ro \\\n",
    "    protophen:gpu \\\n",
    "    python scripts/serve.py \\\n",
    "        --checkpoint /app/checkpoints/best.pt \\\n",
    "        --device cuda\n",
    "```\n",
    "\n",
    "### 7.3 Docker Compose\n",
    "\n",
    "```bash\n",
    "# Start all services (API + optional Prometheus)\n",
    "docker compose -f docker/docker-compose.yml up -d\n",
    "\n",
    "# Check logs\n",
    "docker compose -f docker/docker-compose.yml logs -f protophen-api\n",
    "\n",
    "# Stop\n",
    "docker compose -f docker/docker-compose.yml down\n",
    "```\n",
    "\n",
    "### 7.4 Batch Inference in Docker\n",
    "\n",
    "```bash\n",
    "docker run \\\n",
    "    -v ./data:/app/data \\\n",
    "    -v ./checkpoints:/app/checkpoints:ro \\\n",
    "    protophen:latest \\\n",
    "    python scripts/batch_inference.py \\\n",
    "        --input /app/data/proteins.fasta \\\n",
    "        --checkpoint /app/checkpoints/best.pt \\\n",
    "        --output /app/data/predictions.parquet \\\n",
    "        --uncertainty\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4845e60",
   "metadata": {},
   "source": [
    "## 8. Configuration Reference\n",
    "\n",
    "The deployment is configured via `configs/deployment.yaml`.\n",
    "\n",
    "> **NOTE:** CLI flags override YAML values.\n",
    "\n",
    "```yaml\n",
    "logging:\n",
    "  level: \"INFO\"\n",
    "  log_file: null\n",
    "\n",
    "pipeline:\n",
    "  checkpoint_path: null\n",
    "  esm_model_name: \"esm2_t33_650M_UR50D\"\n",
    "  device: \"auto\"\n",
    "  use_fp16: true\n",
    "  include_physicochemical: true\n",
    "  max_batch_size: 64\n",
    "  max_sequence_length: 2000\n",
    "  default_mc_samples: 20\n",
    "\n",
    "api:\n",
    "  host: \"0.0.0.0\"\n",
    "  port: 8000\n",
    "  workers: 1\n",
    "  reload: false\n",
    "\n",
    "monitoring:\n",
    "  window_size: 1000\n",
    "  enable_drift_detection: true\n",
    "  drift_significance: 0.01\n",
    "  track_regression_metrics: true\n",
    "\n",
    "registry:\n",
    "  registry_dir: \"./model_registry\"\n",
    "  max_versions: 20\n",
    "\n",
    "feedback:\n",
    "  persist_dir: \"./data/feedback\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363cf4ba",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "| Component | Class / Function | Purpose |\n",
    "|-----------|-----------------|---------|\n",
    "| **Pipeline** | `InferencePipeline` | seq → embedding → prediction |\n",
    "| **Checkpoint** | `load_checkpoint()` | Normalise any checkpoint format |\n",
    "| **Checkpoint** | `build_model_from_checkpoint()` | Reconstruct model from checkpoint |\n",
    "| **Registry** | `ModelRegistry` | Version, promote, rollback |\n",
    "| **Registry** | `register_from_trainer_checkpoint()` | Auto-extract Trainer metadata |\n",
    "| **Monitor** | `PredictionMonitor` | Latency, throughput, errors |\n",
    "| **Drift** | `DriftDetector` | KS-test distribution shift |\n",
    "| **Quality** | `PredictionQualityTracker` | Feedback-based R², MSE, Pearson |\n",
    "| **API** | `create_app()` | FastAPI application factory |\n",
    "| **CLI** | `scripts/serve.py` | Launch API server |\n",
    "| **CLI** | `scripts/batch_inference.py` | Batch processing with resume |\n",
    "| **Docker** | `docker/Dockerfile` | CPU container |\n",
    "| **Docker** | `docker/Dockerfile.gpu` | GPU container |\n",
    "\n",
    "**Next steps:**\n",
    "- Addition of the phenotype autoencoder and two-phase pre-training\n",
    "- The autoencoder's latent space will become the prediction target,\n",
    "  further improving the serving pipeline's output quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315cee1a",
   "metadata": {},
   "source": [
    "---\n",
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "24014272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporary files cleaned up.\n"
     ]
    }
   ],
   "source": [
    "if _FASTAPI_AVAILABLE:\n",
    "    client.__exit__(None, None, None)\n",
    "\n",
    "shutil.rmtree(WORK_DIR, ignore_errors=True)\n",
    "print(\"Temporary files cleaned up.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
